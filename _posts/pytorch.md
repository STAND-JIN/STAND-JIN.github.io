# -*- coding: utf-8 -*-
"""PyTorch.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1UI9lg16LZyMx5kZi9MaGfkFTDtodkL4M

## 1. 벡터, 행렬 그리고 텐서(Vector, Matrix and Tensor)

### 1) 벡터, 행렬, 텐서 그림으로 이해하기
"""



"""## 2. Numpy로 Tensor 만들기(벡터와 행렬 만들기)"""

import numpy as np

"""### 1) 1D w/ Numpy"""

t = np.array([0., 1., 2., 3., 4., 5., 6. ])
print(t)

print('Rank of t: ', t.ndim)
print('Shape of t: ', t.shape)

"""#### 1-1) Numpy 기초 이해하기"""

# 인덱스를 통한 원소 접근
print('t[0] t[1] t[-1] = ', t[0], t[1], t[-1])

# [시작 번호 : 끝 번호]로 범위 지정을 통해 가져옴
# [: 끝 번호]는 끝 번호 생략
print('t[2:5] t[4:1] = ', t[2:5], t[4:-1])

# 시작 번호를 생략한 경우와 끝 번호를 생략한 경우
print('t[:2] t[:3] = ', t[:2], t[3:])

"""### 2) 2D w/ Numpy"""

t = np.array([[1., 2., 3.], [4., 5., 6.], [7., 8., 9.], [10., 11., 12.]])
print(t)

print('Rank of t: ', t.ndim)
print('Shape of t: ', t.shape)

"""## 3. 파이토치 텐서 선언하기(PyTorch Tensor Allocation)"""

import torch

"""### 1) 1D w/ PyTorch"""

t = torch.FloatTensor([0., 1., 2., 3., 4., 5., 6.])
print(t)

# rank == 차원
print(t.dim())

# shape
print(t.shape)
print(t.size())

# 인덱스로 접근
print(t[0], t[1], t[-1])
# 슬라이싱
print(t[2:5], t[4:-1])
# 슬라이싱
print(t[:2], t[3:])

"""### 2) 2D w/ PyTorch"""

t = torch.FloatTensor([[1., 2., 3.],
                       [4., 5., 6.],
                       [7., 8., 9.],
                       [10., 11., 12.]
                       ])
print(t)

# rank == 차원
print(t.dim())
# shape
print(t.size())

# 첫번째 차원을 전체 선택한 상황에서 두번째 차원의 첫번째 것만 가져옴
print(t[:, 1])
# 크기
print(t[:, 1].size())

# 첫번째 차원을 전체 선택한 상황에서 마지막 차원의 첫번째 것만 가져옴
print(t[:, -1])
# 크기
print(t[:, -1].size())

# 첫번째 차원을 전체 선택한 상황에서 두번째 차원에서는 맨 마지막에서 첫번째를 제외하고 다 가져옴
print(t[:, :-1])

"""## 3) 브로드캐스팅(Broadcasting)"""

m1 = torch.FloatTensor([[3, 3]])
m2 = torch.FloatTensor([[2, 2]])
print(m1 + m2)

# Vector + scalar
m1 = torch.FloatTensor([[1, 2]])
m2 = torch.FloatTensor([3])       # [3] -> [3, 3]
print(m1 + m2)

# 2 X 1 Vector + 1 X 2 Vector
m1 = torch.FloatTensor([[1, 2]])
m2 = torch.FloatTensor([[3], [4]])
print(m1 + m2)   # 브로드캐스팅 과정에서 실제로 두 텐서가 어떻게 변경되는지 확인해보자.

"""## 4) 자주 사용되는 기능들"""

